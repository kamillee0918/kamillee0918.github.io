---
layout: post
title: "ë¹„ë™ê¸° íŒŒì´ì¬ ê¸°ë°˜ LLM API êµ¬í˜„: OpenAI API, Redis, Asyncio í™œìš©"
date: 2025-05-20 12:27:10 +0900
last_modified_at: 2025-05-25 22:41:16 +0900
tags: [ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°, FastAPI, LLM]
toc: true
---

## ğŸ“‘ **Table Of Contents**

- [1. âš™ ë¹„ë™ê¸° LLM APIì˜ ê°œë…](#async-llm-basics)
  - [ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°ì˜ í•„ìš”ì„±](#why-async)
  - [Python ë¹„ë™ê¸° ê¸°ì´ˆì™€ Asyncio](#asyncio-basics)
  - [ì• í”Œë¦¬ì¼€ì´ì…˜ ë‹¤ì´ì–´ê·¸ë¨](#application-diagram)
- [2. âš™ OpenAI API ë¹„ë™ê¸° í˜¸ì¶œ](#openai-async)
  - [AsyncOpenAI ë° aiohttp í™œìš©](#asyncopenai-usage)
  - [ë™ì‹œì„±/ë°°ì¹˜ ì²˜ë¦¬](#concurrency-batching)
- [3. âš™ FastAPI ê¸°ë°˜ ë¹„ë™ê¸° LLM ì„œë¹„ìŠ¤ ì„¤ê³„](#fastapi-design)
  - [ì—”ë“œí¬ì¸íŠ¸ ì„¤ê³„ ë° ì˜ˆì‹œ](#endpoint-design)
- [4. âš™ Redisë¥¼ í™œìš©í•œ ìƒíƒœ ê´€ë¦¬ ë° ìºì‹±](#redis-integration)
  - [ë¹„ë™ê¸° Redis í´ë¼ì´ì–¸íŠ¸ í™œìš©](#async-redis)
  - [ì‘ì—… ìƒíƒœ ì¶”ì  ë° TTL ê´€ë¦¬](#task-tracking)
- [5. âš™ ì „ì²´ êµ¬ì¡° ë° ì½”ë“œ ì˜ˆì‹œ](#full-example)
- [6. âš™ ê³ ë ¤ì‚¬í•­ ë° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤](#considerations)
- [7. ğŸ ë§ˆì¹˜ë©°](#conclusion)

---

![async-python-1.png](/images/posts/2025-05-20-asynchronous-python/async-python-1.png)

## 1. âš™ ë¹„ë™ê¸° LLM APIì˜ ê°œë… {#async-llm-basics}

### ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°ì˜ í•„ìš”ì„± {#why-async}

ëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸(LLM) APIë¥¼ í™œìš©í•  ë•Œ, ë‹¤ìˆ˜ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©´ ë„¤íŠ¸ì›Œí¬ ì§€ì—°ê³¼ ì‘ë‹µ ëŒ€ê¸° ë•Œë¬¸ì— ì „ì²´ ì²˜ë¦¬ ì‹œê°„ì´ í¬ê²Œ ëŠ˜ì–´ë‚©ë‹ˆë‹¤.

ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°ì„ ì ìš©í•˜ë©´ ì—¬ëŸ¬ ìš”ì²­ì„ ë™ì‹œì— ì²˜ë¦¬í•  ìˆ˜ ìˆì–´ ì²˜ë¦¬ëŸ‰(throughput)ì´ ë¹„ì•½ì ìœ¼ë¡œ ì¦ê°€í•˜ê³ , ì‘ë‹µ ëŒ€ê¸° ì‹œê°„ì„ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Python ë¹„ë™ê¸° ê¸°ì´ˆì™€ Asyncio {#asyncio-basics}

Pythonì˜ **asyncio** ëª¨ë“ˆì€ ì½”ë£¨í‹´, ì´ë²¤íŠ¸ ë£¨í”„, Future ê°ì²´ë¥¼ í™œìš©í•´ ë¹„ë™ê¸° ì½”ë“œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.

- **ì½”ë£¨í‹´**: `async def`ë¡œ ì •ì˜, `await`ë¡œ ì¼ì‹œ ì¤‘ë‹¨ ë° ì¬ê°œ

- **ì´ë²¤íŠ¸ ë£¨í”„**: ë¹„ë™ê¸° ì‘ì—…ì„ ê´€ë¦¬

- **awaitables**: `await`ë¡œ ëŒ€ê¸° ê°€ëŠ¥í•œ ê°ì²´

- **ì›Œì»¤(Worker)**: ì‘ì—… íì—ì„œ ì‘ì—…ì„ ê°€ì ¸ì™€ ì‹¤í–‰í•˜ëŠ” ì†Œë¹„ì(consumer) ì—­í• ì„ í•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜ë¡œ, ì—¬ëŸ¬ ì›Œì»¤ê°€ ë™ì‹œì— ì‹¤í–‰ë˜ì–´ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ êµ¬í˜„

```python
import asyncio

async def greet(name):
    await asyncio.sleep(1)
    print(f"Hello, {name}!")


async def main():
    await asyncio.gather(
        greet("Kamil Lee"),
        greet("parousia0918")
    )

asyncio.run(main())
```

ì´ì²˜ëŸ¼ ì—¬ëŸ¬ ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì• í”Œë¦¬ì¼€ì´ì…˜ ë‹¤ì´ì–´ê·¸ë¨ {#application-diagram}

í•´ë‹¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬í˜„í•˜ê¸° ìœ„í•œ ë‹¤ì´ì–´ê·¸ë¨ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. ì „ì²´ì ì¸ ë§¥ë½ì„ íŒŒì•…í•˜ëŠ” ë° ë„ì›€ì´ ë˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤.

![async-python-2.png](/images/posts/2025-05-20-asynchronous-python/async-python-2.png)

- **ì „ì²´ ì•„í‚¤í…ì²˜ ê°œìš”**: ì´ ë‹¤ì´ì–´ê·¸ë¨ì€ **ë¹„ë™ê¸° LLM API ì‹œìŠ¤í…œ**ì˜ ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì‹œìŠ¤í…œì€ **ì´ë²¤íŠ¸ ê¸°ë°˜ ë¹„ë™ê¸° ì²˜ë¦¬**ë¥¼ í†µí•´ ë†’ì€ ì²˜ë¦¬ëŸ‰ê³¼ íš¨ìœ¨ì ì¸ ìì› í™œìš©ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

- **ì»´í¬ë„ŒíŠ¸ë³„ ìƒì„¸ ë¶„ì„**
  - **Client(í´ë¼ì´ì–¸íŠ¸)**: í´ë¼ì´ì–¸íŠ¸ëŠ” ì‹œìŠ¤í…œì˜ ì§„ì…ì ìœ¼ë¡œ, ë‹¤ìŒê³¼ ê°™ì€ ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    - **ìš”ì²­ ì „ì†¡**: ì—¬ëŸ¬ ê°œì˜ í”„ë¡¬í”„íŠ¸ë¥¼ í¬í•¨í•œ ë°°ì¹˜ ìš”ì²­ì„ FastAPI ì„œë²„ë¡œ ì „ì†¡
    - **ë¹„ë™ê¸° ì‘ë‹µ ì²˜ë¦¬**: ì¦‰ì‹œ task_id ëª©ë¡ì„ ë°›ì•„ ë¹„ë™ê¸°ì ìœ¼ë¡œ ê²°ê³¼ ì¡°íšŒ
    - **í´ë§ ë˜ëŠ” ì›¹ì†Œì¼“**: ì‘ì—… ì™„ë£Œ ìƒíƒœë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ í™•ì¸í•˜ê±°ë‚˜ ì‹¤ì‹œê°„ ì•Œë¦¼ ìˆ˜ì‹ 

  - **FastAPI Server(ì›¹ ì„œë²„)**: FastAPI ì„œë²„ëŠ” ë¹„ë™ê¸° ì›¹ í”„ë ˆì„ì›Œí¬ë¡œì„œ í•µì‹¬ ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    - **async endpoint(ë¹„ë™ê¸° ì—”ë“œí¬ì¸íŠ¸)**
      - `POST /api/tasks`: í”„ë¡¬í”„íŠ¸ ë°°ì¹˜ë¥¼ ë°›ì•„ ê°ê°ì— UUID ê¸°ë°˜ task_id í• ë‹¹
      - `GET /api/tasks`: ì‰¼í‘œë¡œ êµ¬ë¶„ëœ task_idë“¤ì˜ ìƒíƒœ ë° ê²°ê³¼ ì¡°íšŒ
      - `Non-blocking I/O`: ê° ìš”ì²­ì´ I/O ëŒ€ê¸° ì¤‘ì—ë„ ë‹¤ë¥¸ ìš”ì²­ì„ ë™ì‹œ ì²˜ë¦¬
    - **ì£¼ìš” íŠ¹ì§•**
      - **Pydantic í†µí•©**: ìë™ ìš”ì²­/ì‘ë‹µ ê²€ì¦ ë° ì§ë ¬í™”
      - **Starlette ê¸°ë°˜**: ASGI ì„œë²„ë¡œ ë†’ì€ ë™ì‹œì„± ì§€ì›
      - **lifespan ì´ë²¤íŠ¸**: ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘/ì¢…ë£Œ ì‹œ ìì› ê´€ë¦¬

  - **Task Queue(ì‘ì—… í)**: `asyncio.Queue`ë¥¼ í™œìš©í•œ **ìƒì‚°ì-ì†Œë¹„ì íŒ¨í„´**ì˜ í•µì‹¬ì…ë‹ˆë‹¤.
    - **í ë™ì‘ ë°©ì‹**
      - **FIFO(First In, First Out)**: ë¨¼ì € ë“¤ì–´ì˜¨ ì‘ì—…ë¶€í„° ìˆœì°¨ ì²˜ë¦¬
      - **ë°±í”„ë ˆì…” ì œì–´**: í í¬ê¸° ì œí•œìœ¼ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°ì ˆ
      - **ë¹„ë™ê¸° put/get**: í ì¡°ì‘ ì‹œ ì´ë²¤íŠ¸ ë£¨í”„ ë¸”ë¡œí‚¹ ë°©ì§€
    - **enqueue task(ì‘ì—… ì¶”ê°€)**

      ```python
      await task_queue.put((task_id, prompt))
      ```

  - **Async Workers(ë¹„ë™ê¸° ì›Œì»¤ë“¤)**: ì—¬ëŸ¬ ì›Œì»¤ê°€ **ë™ì‹œì— ì‹¤í–‰**ë˜ì–´ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
    - **ì›Œì»¤ íŠ¹ì§•**
      - **ê³ ì • ì›Œì»¤ í’€**: ì‹œìŠ¤í…œ ìì›ì— ë§ê²Œ ì›Œì»¤ ìˆ˜ ì¡°ì ˆ (ì¼ë°˜ì ìœ¼ë¡œ CPU ì½”ì–´ x 2)
      **ë…ë¦½ì  ì‹¤í–‰**: ê° ì›Œì»¤ëŠ” ë³„ë„ ì½”ë£¨í‹´ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´ ì„œëŸ¬ ê°„ì„­í•˜ì§€ ì•ŠìŒ
      **Graceful ì¢…ë£Œ**: ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ í˜„ì¬ ì‘ì—… ì™„ë£Œ í›„ ì•ˆì „í•˜ê²Œ ì¢…ë£Œ
    - **ì›Œì»¤ ì‹¤í–‰ íë¦„**

      ```python
      async def background_worker(redis_client, task_queue):
        while True:
            task_id, prompt = await task_queue.get()
            await process_llm_task(redis_client, task_id, prompt)
            task_queue.task_done()
      ```

  - **Redis(ìƒíƒœ ì €ì¥ì†Œ)**: ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ë¥¼ í†µí•œ ìƒíƒœ ê´€ë¦¬ ë° ìºì‹±
    - **ì£¼ìš” ê¸°ëŠ¥**
      - **ì‘ì—… ìƒíƒœ ì¶”ì **: `task:{task_id}` í‚¤ë¡œ ê° ì‘ì—…ì˜ ì§„í–‰ ìƒí™© ì €ì¥
      - **ê²°ê³¼ ìºì‹±**: ì™„ë£Œëœ ì‘ì—…ì˜ ê²°ê³¼ë¥¼ ì„ì‹œ ì €ì¥
      - **TTL ê´€ë¦¬**: ìë™ ë§Œë£Œë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í™•ë³´
    - **ìƒíƒœ ì „ì´**

      ```text
      queued -> processing -> completed/error
      ```

    - **store result(ê²°ê³¼ ì €ì¥)**

      ```python
      await redis_client.hset(f"task:{task_id}", mapping={
        "status": "completed",
        "result": llm_response,
        "timestamp": datetime.now().isoformat()
      })
      ```

  - **OpenAI API(ì™¸ë¶€ LLM ì„œë¹„ìŠ¤)**: `AsyncOpenAI`ë¥¼ í†µí•œ ë¹„ë™ê¸° API í˜¸ì¶œ
    - **ë¹„ë™ê¸° í˜¸ì¶œì˜ ì¥ì **
      - **ë„¤íŠ¸ì›Œí¬ ëŒ€ê¸° ì‹œê°„ í™œìš©**: API ì‘ë‹µ ëŒ€ê¸° ì¤‘ ë‹¤ë¥¸ ì‘ì—… ì²˜ë¦¬ ê°€ëŠ¥
      - **ë™ì‹œ ìš”ì²­ ì²˜ë¦¬**: ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ë¥¼ ë³‘ë ¬ë¡œ OpenAI APIì— ì „ì†¡
      - **ì—ëŸ¬ ê²©ë¦¬**: ê°œë³„ ìš”ì²­ ì‹¤íŒ¨ê°€ ì „ì²´ ì‹œìŠ¤í…œì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠìŒ

---

## 2. âš™ OpenAI API ë¹„ë™ê¸° í˜¸ì¶œ {#openai-async}

### AsyncOpenAI í™œìš© {#asyncopenai-usage}

OpenAI ê³µì‹ Python í´ë¼ì´ì–¸íŠ¸ëŠ” ë¹„ë™ê¸° ì‚¬ìš©ì„ ì§€ì›í•©ë‹ˆë‹¤.

- `AsyncOpenAI`ì™€ ê°™ì€ ë¹„ë™ê¸° ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì‘ë‹µì„ ë³‘ë ¬ë¡œ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
# app/routers/router.py
from openai import AsyncOpenAI

# LLM ì‘ì—… ì²˜ë¦¬ í•¨ìˆ˜
async def process_llm_task(redis_client: redis.Redis, task_id: str, prompt: str):
    """LLM ì‘ì—… ì²˜ë¦¬ í•¨ìˆ˜"""

    # ... Redis ì„¤ì • ê´€ë ¨ ìƒëµ ...

    try:
        # ... Redis ìƒíƒœ ì—…ë°ì´íŠ¸ ê´€ë ¨ ìƒëµ ...

        # OpenAI API í˜¸ì¶œ
        client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))

        try:
            # OpenAI ê³µì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ìµœì‹  ë¹„ë™ê¸° í˜¸ì¶œ ë°©ì‹ì„ ì‚¬ìš©
            response = await client.chat.completions.create(
                model="gpt-3.5-turbo", # GPT-3.5 Turbo ëª¨ë¸ ì‚¬ìš©
                messages=[
                    {"role": "user", "content": prompt} # ë©”ì‹œì§€ í˜•ì‹ ì‚¬ìš©
                ],
                max_tokens=100,
                temperature=0.7,
                timeout=30.0 # API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ ì„¤ì • (ì´ˆ)
            )

            # ... ê²°ê³¼ íŒŒì‹± ë° Redis ìƒíƒœ ì—…ë°ì´íŠ¸ ê´€ë ¨ ìƒëµ ...

        # ì˜ˆì™¸ ì²˜ë¦¬
        except Exception as e:
            ...

    except Exception as e:
        ...
```

ì´ ë°©ì‹ìœ¼ë¡œ ì—¬ëŸ¬ ìš”ì²­ì„ ë™ì‹œì— ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ë™ì‹œì„±/ë°°ì¹˜ ì²˜ë¦¬ {#concurrency-batching}

- **ë™ì‹œì„± ì œì–´**: `asyncio.Queue`ì™€ ê³ ì •ëœ ìˆ˜ì˜ ì›Œì»¤(consumer)ë¥¼ í™œìš©í•´, íì— ìŒ“ì¸ ì‘ì—…ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤. ê° ì›Œì»¤ëŠ” íì—ì„œ ì‘ì—…ì„ ê°€ì ¸ì™€ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ë…ë¦½ì ì¸ ì†Œë¹„ì(consumer)ë¡œ, ì›Œì»¤ ìˆ˜ë¥¼ ì ì ˆíˆ ì¡°ì ˆí•¨ìœ¼ë¡œì¨ ë™ì‹œì— ì²˜ë¦¬ë˜ëŠ” ì‘ì—… ìˆ˜ë¥¼ ì œí•œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- **ë°°ì¹˜ ì²˜ë¦¬**: ë‹¨ì¼ API í˜¸ì¶œë¡œ ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ, ë‹¤ìˆ˜ì˜ ê°œë³„ í”„ë¡¬í”„íŠ¸ ì‘ì—…ì„ íì— ë„£ê³  ì—¬ëŸ¬ ì›Œì»¤ê°€ ì´ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë§ì€ ì–‘ì˜ ì‘ì—…ì„ ë³´ë‹¤ íš¨ìœ¨ì ìœ¼ë¡œ ë¶„ì‚° ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©°, ìì›ì„ ìµœì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## 3. âš™ FastAPI ê¸°ë°˜ ë¹„ë™ê¸° LLM ì„œë¹„ìŠ¤ ì„¤ê³„ {#fastapi-design}

FastAPIëŠ” íŒŒì´ì¬ ë¹„ë™ê¸° ì½”ë“œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì§€ì›í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì´ë©°, [Starlette](https://www.starlette.io/)ê³¼ [Pydantic](https://docs.pydantic.dev/latest/)ì„ ê¸°ë°˜ìœ¼ë¡œ ë¹„ë™ê¸° I/Oì˜ ì¥ì ì„ ìµœëŒ€í•œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

- **Non-blocking I/O**: ì „í†µì ì¸ ë™ê¸°ì‹ ì›¹ ì„œë²„ì™€ ë‹¬ë¦¬, FastAPIëŠ” ê° ìš”ì²­ì´ I/O ì‘ì—…ì„ ê¸°ë‹¤ë¦¬ëŠ” ë™ì•ˆ ë‹¤ë¥¸ ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆì–´ ë™ì¼ í•˜ë“œì›¨ì–´ì—ì„œ ë” ë§ì€ ë™ì‹œ ì—°ê²°ì„ ì²˜ë¦¬

- **ì´ë²¤íŠ¸ ë£¨í”„ í™œìš©**: asyncioì˜ ì´ë²¤íŠ¸ ë£¨í”„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ ëŒ€ëŸ‰ì˜ ë™ì‹œ ì—°ê²°ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬

- **ë¹„ë™ê¸° ë¼ìš°íŒ…**: ë¼ìš°íŠ¸ í•¸ë“¤ëŸ¬ë¥¼ `async def`ë¡œ ì •ì˜í•˜ì—¬ ë¹„ë™ê¸° ì²˜ë¦¬ê°€ í•„ìš”í•œ ì‘ì—…(ì™¸ë¶€ API í˜¸ì¶œ, DB ì¿¼ë¦¬ ë“±)ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬

### ì—”ë“œí¬ì¸íŠ¸ ì„¤ê³„ ë° ì˜ˆì‹œ {#endpoint-design}

FastAPIëŠ” Python ë¹„ë™ê¸° ì½”ë“œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì§€ì›í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

- `POST /api/tasks`: ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì•„ ë¹„ë™ê¸° ì‘ì—… ìƒì„±, ê° ì‘ì—…ì— ê³ ìœ  task_id ë¶€ì—¬
- `GET /api/tasks`: ì‘ì—… ìƒíƒœ(progress/result) ì¡°íšŒ

```python
# app/routers/router.py
@router.post("/tasks")
async def create_tasks(prompts: PromptList):
    """í”„ë¡¬í”„íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ íì— ì¶”ê°€í•˜ê³  ì‘ì—… IDë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    task_ids = []

    if not prompts or not prompts.prompts:
         raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="í”„ë¡¬í”„íŠ¸ ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")


    logger.info(f"{len(prompts.prompts)}ê°œì˜ ìƒˆ ì‘ì—… ìƒì„± ìš”ì²­ ìˆ˜ì‹ ")

    for prompt in prompts.prompts:
        task_id = str(uuid.uuid4())
        # íì— ì‘ì—… ì¶”ê°€
        await task_queue.put((task_id, prompt))
        task_ids.append(task_id)
        logger.debug(f"ì‘ì—… {task_id} íì— ì¶”ê°€ë¨")

    logger.info(f"{len(task_ids)}ê°œì˜ ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ íì— ì¶”ê°€ë¨")
    # ì‘ë‹µ ì‹œ ìƒíƒœë¥¼ 'queued' ë“±ìœ¼ë¡œ í‘œì‹œ
    return {"task_ids": task_ids, "status": "queued"}

@router.get("/tasks")
async def get_task_status(task_ids: str, request: Request) -> Dict[str, TaskStatus | Dict[str, str]]: # ì‘ë‹µ íƒ€ì… íŒíŠ¸ ê°œì„ 
    """ì‘ì—… ìƒíƒœë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    logger.info(f"ì‘ì—… ìƒíƒœ ì¡°íšŒ ìš”ì²­ ìˆ˜ì‹  (task_ids: {task_ids})")

    # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì‘ì—… ID ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶„ë¦¬
    task_id_list = [id.strip() for id in task_ids.split(",") if id.strip()]

    if not task_id_list:
         raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="ìœ íš¨í•œ ì‘ì—… IDë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")

    res = {}
    # Redis í´ë¼ì´ì–¸íŠ¸ë¥¼ request.app.stateì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    redis_client = request.app.state.redis_client

    for task_id in task_id_list:
        # Redisì—ì„œ ì‘ì—… ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        try:
            task_data = await redis_client.hgetall(f"task:{task_id}")
            if task_data:
                # TaskStatus ëª¨ë¸ì— ë§ì¶° ë°ì´í„°ë¥¼ êµ¬ì„± (ë˜ëŠ” ì›ì‹œ ë°ì´í„° ë°˜í™˜)
                res[task_id] = TaskStatus(**task_data).model_dump() # Pydantic ëª¨ë¸ ì‚¬ìš© ì˜ˆì‹œ
            else:
                # Redisì— ì‘ì—… ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
                res[task_id] = {"status": "not_found"}
            logger.debug(f"ì‘ì—… {task_id} ìƒíƒœ ì¡°íšŒ ê²°ê³¼: {res[task_id]}")
        except ValidationError as e:
            logger.warning(f"ì‘ì—… {task_id}: TaskStatus ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨ - {e}")
            res[task_id] = task_data  # ì›ì‹œ ë°ì´í„° ë°˜í™˜
        except Exception as e:
            logger.error(f"ì‘ì—… {task_id} ìƒíƒœ ì¡°íšŒ ì¤‘ Redis ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            res[task_id] = {"status": "error", "error": "Failed to retrieve status from Redis"}

    return res
```

ì´ êµ¬ì¡°ë¥¼ í™•ì¥í•´ ì‘ì—… í, ìƒíƒœ ì¶”ì , ìºì‹± ë“±ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## 4. âš™ Redisë¥¼ í™œìš©í•œ ìƒíƒœ ê´€ë¦¬ ë° ìºì‹± {#redis-integration}

### ë¹„ë™ê¸° Redis í´ë¼ì´ì–¸íŠ¸ í™œìš© {#async-redis}

- **aioredis** ë˜ëŠ” **redis.asyncio**ë¥¼ ì‚¬ìš©í•˜ë©´ Redisì™€ ë¹„ë™ê¸°ì ìœ¼ë¡œ í†µì‹ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- ì‘ì—…ë³„ ìƒíƒœ(progress/result) ì €ì¥ ë° TTL(Time-To-Live)ë¡œ ë§Œë£Œ ê´€ë¦¬

```python
# app/main.py
from contextlib import asynccontextmanager
from dotenv import load_dotenv
from fastapi import FastAPI

import asyncio
import os
import redis.asyncio as redis
import logging

# ... ë¡œê¹…, í™˜ê²½ë³€ìˆ˜ í˜¸ì¶œ ë“± ìƒëµ ...

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬ í•¨ìˆ˜"""
    logger.info("ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘: Redis í´ë¼ì´ì–¸íŠ¸ ë° ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ì´ˆê¸°í™”")

    # Redis í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ë° ìƒíƒœì— ì €ì¥
    try:
        app.state.redis_client = redis.Redis(
            host=os.getenv('REDIS_HOST'),
            port=int(os.getenv('REDIS_PORT', 6379)),
            db=int(os.getenv('REDIS_DB', 0)),
            decode_responses=True, # ë¬¸ìì—´ë¡œ ë°ì´í„°ë¥¼ ì²˜ë¦¬
            socket_connect_timeout=5,
            socket_timeout=5,
            retry_on_timeout=True
        )
        # Redis ì—°ê²° í™•ì¸
        await app.state.redis_client.ping()
        logger.info("Redis í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì„±ê³µ")
    except Exception as e:
        logger.critical(f"Redis í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ë˜ëŠ” ì—°ê²° ì‹¤íŒ¨: {e}", exc_info=True)
        # Redis ì—°ê²° ì‹¤íŒ¨ ì‹œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ì„ ì¤‘ë‹¨í•˜ê±°ë‚˜,
        # API ìš”ì²­ ì‹œ Redis ì—°ê²° ì¬ì‹œë„ ë¡œì§ì„ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.
        # ì—¬ê¸°ì„œëŠ” ë¡œê¹…ë§Œ í•˜ê³  ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ê³„ì† ì§„í–‰í•˜ë„ë¡ í•©ë‹ˆë‹¤.
        # í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ë” ê²¬ê³ í•œ ì²˜ë¦¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        raise e  # ë˜ëŠ” ì ì ˆí•œ fallback ë¡œì§ êµ¬í˜„

    # ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ì‹œì‘
    from routers.router import background_worker, task_queue # router.pyì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    for _ in range(NUM_WORKERS):
        # asyncio.create_taskë¥¼ ì‚¬ìš©í•˜ì—¬ ì›Œì»¤ ì½”ë£¨í‹´ì„ ìŠ¤ì¼€ì¤„ë§í•©ë‹ˆë‹¤.
        task = asyncio.create_task(background_worker(app.state.redis_client, task_queue))
        worker_tasks.append(task)
    logger.info(f"{NUM_WORKERS}ê°œì˜ ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ì‹œì‘ë¨")

    # yieldë¥¼ í†µí•´ ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ë™
    yield

    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ ì •ë¦¬ ì‘ì—…
    logger.info("ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ: ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ë° Redis í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬")

    # íê°€ ë¹Œ ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ê±°ë‚˜, ë‚¨ì€ ì‘ì—…ì„ ì·¨ì†Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì›Œì»¤ íƒœìŠ¤í¬ë“¤ì„ ì·¨ì†Œí•©ë‹ˆë‹¤.
    for task in worker_tasks:
        task.cancel()
    # ì·¨ì†Œê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
    await asyncio.gather(*worker_tasks, return_exceptions=True)
    logger.info("ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ì •ë¦¬ ì™„ë£Œ")

    # Redis í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ
    if hasattr(app.state, 'redis_client') and app.state.redis_client:
        await app.state.redis_client.aclose()
        logger.info("Redis í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ")

# ... FastAPI í˜¸ì¶œ ë° main í•¨ìˆ˜ ìƒëµ ...

```

ì´ì²˜ëŸ¼ ì‘ì—…ë³„ë¡œ ìƒíƒœ/ê²°ê³¼ë¥¼ ì €ì¥í•˜ê³  ë§Œë£Œì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì‘ì—… ìƒíƒœ ì¶”ì  ë° TTL ê´€ë¦¬ {#task-tracking}

- ì‘ì—… ìƒì„± ì‹œ UUIDë¡œ task_id ìƒì„±, Redisì— `status: pending` ì €ì¥
- ì‘ì—… ì™„ë£Œ í›„ `status: completed`, ê²°ê³¼ ì €ì¥
- TTLë¡œ 24ì‹œê°„ ë“± ìë™ ë§Œë£Œ ì„¤ì •
- GET ì—”ë“œí¬ì¸íŠ¸ì—ì„œ task_idë¡œ ìƒíƒœ/ê²°ê³¼ ì¡°íšŒ

---

## 5. âš™ ì „ì²´ êµ¬ì¡° ë° ì½”ë“œ ì˜ˆì‹œ {#full-example}

ì•„ë˜ëŠ” OpenAI API, FastAPI, Redis, Asyncioë¥¼ ê²°í•©í•œ ë¹„ë™ê¸° LLM APIì˜ ì „ì²´ êµ¬ì¡° ì˜ˆì‹œì…ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ë‹¤ìŒê³¼ ê°™ì€ ë¹„ë™ê¸° ì›Œí¬í”Œë¡œìš°ë¥¼ ë”°ë¦…ë‹ˆë‹¤.

1. í´ë¼ì´ì–¸íŠ¸ê°€ `/api/tasks` ì—”ë“œí¬ì¸íŠ¸ë¥¼ í†µí•´ í”„ë¡¬í”„íŠ¸ ëª©ë¡ ì „ì†¡
2. ê° í”„ë¡¬í”„íŠ¸ë§ˆë‹¤ ê³ ìœ  task_id ìƒì„± í›„ ë¹„ë™ê¸° íì— ì¶”ê°€
3. ì—¬ëŸ¬ ì›Œì»¤(ì†Œë¹„ì)ê°€ ë™ì‹œì— íë¥¼ ëª¨ë‹ˆí„°ë§í•˜ë©° ì‘ì—… ì²˜ë¦¬
4. Redisë¥¼ í†µí•œ ì‘ì—… ìƒíƒœ ê´€ë¦¬ ë° ê²°ê³¼ ì €ì¥
5. í´ë¼ì´ì–¸íŠ¸ê°€ `GET /api/tasks` ìš”ì²­ìœ¼ë¡œ ì‘ì—… ìƒíƒœ ë° ê²°ê³¼ ì¡°íšŒ

ì´ëŸ¬í•œ êµ¬ì¡°ëŠ” I/O ë°”ìš´ë“œ ì‘ì—…(API í˜¸ì¶œ, DB ì¿¼ë¦¬ ë“±)ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬í•˜ì—¬, ì‹œìŠ¤í…œ ìì›ì„ ìµœëŒ€í•œ í™œìš©í•˜ë©´ì„œ ë†’ì€ ì²˜ë¦¬ëŸ‰ì„ ì œê³µí•©ë‹ˆë‹¤.

```python
# app/routers/router.py
from fastapi import APIRouter, Request, HTTPException, status
from typing import Any, Dict, List, Union
from pydantic import BaseModel, ValidationError
from openai import AsyncOpenAI
from openai import APIStatusError, APIConnectionError, RateLimitError

import asyncio
import logging
import os
import uuid
import redis.asyncio as redis

logger = logging.getLogger(__name__)

router = APIRouter()

# ë¹„ë™ê¸° ë°©ì‹ì˜ í êµ¬í˜„
# íëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì´ˆê¸°í™”ë˜ê³ , ì›Œì»¤ë“¤ì´ ê³µìœ í•©ë‹ˆë‹¤.
task_queue = asyncio.Queue()

class PromptList(BaseModel):
    """PromptList ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜"""
    prompts: List[str] # í”„ë¡¬í”„íŠ¸ ë¦¬ìŠ¤íŠ¸

# ì‘ì—… ìƒíƒœ ì¡°íšŒë¥¼ ìœ„í•œ ëª¨ë¸ (Optional, Pydantic ì‘ë‹µ ëª¨ë¸ë¡œ ì‚¬ìš© ê°€ëŠ¥)
class TaskStatus(BaseModel):
    """TaskStatus ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜"""
    status: str
    result: Any = None
    error: str = None
    progress: str = None

# ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ í•¨ìˆ˜
async def background_worker(redis_client: redis.Redis, task_queue: asyncio.Queue):
    """ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ í•¨ìˆ˜"""
    logger.info("ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ì‹œì‘ ëŒ€ê¸° ì¤‘")
    while True:
        task_id, prompt = None, None # ì˜ˆì™¸ ë°œìƒ ì‹œ ë¡œê¹…ì„ ìœ„í•´ ì´ˆê¸°í™”
        try:
            # íì—ì„œ ì‘ì—… ê°€ì ¸ì˜¤ê¸°
            task_id, prompt = await task_queue.get()
            logger.info(f"ì‘ì—… {task_id} ì²˜ë¦¬ ì‹œì‘")

            # LLM ì‘ì—… ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ
            await process_llm_task(redis_client, task_id, prompt) # Redis í´ë¼ì´ì–¸íŠ¸ë¥¼ ì¸ìë¡œ ì „ë‹¬

            # ì‘ì—… ì™„ë£Œë¥¼ íì— ì•Œë¦¼
            task_queue.task_done()
            logger.info(f"ì‘ì—… {task_id} ì²˜ë¦¬ ì™„ë£Œ")

        except asyncio.CancelledError:
            # ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ë“±ìœ¼ë¡œ ì¸í•´ íƒœìŠ¤í¬ê°€ ì·¨ì†Œëœ ê²½ìš°
            logger.info("ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ì·¨ì†Œë¨")
            break # ë£¨í”„ ì¢…ë£Œ

        except Exception as error:
            # ì˜ˆìƒì¹˜ ëª»í•œ ë‹¤ë¥¸ ì˜ˆì™¸ ë°œìƒ ì‹œ
            logger.error(f"ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ (task_id: {task_id}): {error}", exc_info=True)
            # íì—ì„œ ì‘ì—…ì„ ì œê±°í•˜ê³  ìƒíƒœë¥¼ ì—ëŸ¬ë¡œ ê¸°ë¡í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
            if task_id:
                try:
                    await redis_client.hset(
                        f"task:{task_id}",
                        mapping={
                            "status": "unexpected_worker_error",
                            "error": f"Worker exception: {error}"
                        }
                    )
                except Exception as redis_err:
                    logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì›Œì»¤ ì—ëŸ¬ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (task_id: {task_id}): {redis_err}", exc_info=True)

            # íì—ì„œ ì‘ì—… ì™„ë£Œ ì²˜ë¦¬ (ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ë‹¤ìŒ ì‘ì—…ì„ ê°€ì ¸ì™€ì•¼ í•˜ë¯€ë¡œ task_done í˜¸ì¶œ)
            if task_id:
                 task_queue.task_done()

            # ì—ëŸ¬ ë°œìƒ ì‹œ ë£¨í”„ë¥¼ ê³„ì† ì§„í–‰í•˜ì—¬ ë‹¤ìŒ ì‘ì—…ì„ ì²˜ë¦¬
            # ë§Œì•½ ë³µêµ¬ ë¶ˆê°€ëŠ¥í•œ ì—ëŸ¬ë¼ë©´ ë£¨í”„ë¥¼ ì¢…ë£Œí•˜ê±°ë‚˜ íŠ¹ì • ë¡œì§ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            continue

# LLM ì‘ì—… ì²˜ë¦¬ í•¨ìˆ˜
async def process_llm_task(redis_client: redis.Redis, task_id: str, prompt: str):
    """LLM ì‘ì—… ì²˜ë¦¬ í•¨ìˆ˜"""
    logger.info(f"LLM ì‘ì—… ì²˜ë¦¬ ì‹œì‘ (task_id: {task_id})")

    # Redis í‚¤ ì´ë¦„ ìƒìˆ˜í™” (ê°€ë…ì„± ë° ê´€ë¦¬ ìš©ì´ì„± í–¥ìƒ)
    TASK_REDIS_KEY = f"task:{task_id}"
    # ì‘ì—… ìƒíƒœ ë° ê²°ê³¼ ë§Œë£Œ ì‹œê°„ (ì´ˆ)
    TASK_TTL_SECONDS = 86400 # 24ì‹œê°„

    try:
        # Redis ìƒíƒœë¥¼ "processing"ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        await redis_client.hset(
            TASK_REDIS_KEY,
            mapping={
                "status": "processing",
                "progress": "0" # í”„ë¡œê·¸ë ˆìŠ¤ëŠ” í•„ìš”ì— ë”°ë¼ ì—…ë°ì´íŠ¸
            }
        )
        # TTL ì„¤ì • (í‚¤ê°€ ì—†ìœ¼ë©´ ì„¤ì •ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ, hset ì´í›„ì— í˜¸ì¶œ)
        await redis_client.expire(TASK_REDIS_KEY, TASK_TTL_SECONDS)
        logger.debug(f"ì‘ì—… {task_id}: Redis ìƒíƒœ 'processing' ì—…ë°ì´íŠ¸ ë° TTL ì„¤ì •")

        # OpenAI API í˜¸ì¶œ
        client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        logger.debug(f"ì‘ì—… {task_id}: OpenAI API í˜¸ì¶œ ì¤€ë¹„")

        try:
            # OpenAI ê³µì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ìµœì‹  ë¹„ë™ê¸° í˜¸ì¶œ ë°©ì‹ì„ ì‚¬ìš©
            response = await client.chat.completions.create(
                model="gpt-3.5-turbo", # GPT-3.5 Turbo ëª¨ë¸ ì‚¬ìš©
                messages=[
                    {"role": "user", "content": prompt} # ë©”ì‹œì§€ í˜•ì‹ ì‚¬ìš©
                ],
                max_tokens=100,
                temperature=0.7,
                timeout=30.0 # API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ ì„¤ì • (ì´ˆ)
            )
            logger.debug(f"ì‘ì—… {task_id}: OpenAI API ì‘ë‹µ ìˆ˜ì‹ ")

            # ê²°ê³¼ íŒŒì‹±
            if response.choices and response.choices[0].message:
                 result = response.choices[0].message.content
                 logger.debug(f"ì‘ì—… {task_id}: ê²°ê³¼ ì¶”ì¶œ ì„±ê³µ")
            else:
                 result = "No content in response"
                 logger.warning(f"ì‘ì—… {task_id}: OpenAI ì‘ë‹µì— ê²°ê³¼ ì—†ìŒ")

            # ì‘ì—… ê²°ê³¼ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
            await redis_client.hset(
                TASK_REDIS_KEY,
                mapping={
                    "status": "completed",
                    "result": result,
                    "progress": "100"
                }
            )
            logger.info(f"ì‘ì—… {task_id}: Redis ìƒíƒœ 'completed' ë° ê²°ê³¼ ì—…ë°ì´íŠ¸")
        # OpenAI ê´€ë ¨ ì˜ˆì™¸ ì²˜ë¦¬
        except RateLimitError as e:
            logger.warning(f"ì‘ì—… {task_id}: OpenAI Rate Limit ì´ˆê³¼ - {e}", exc_info=True)
            await redis_client.hset(
                TASK_REDIS_KEY,
                mapping={
                    "status": "error",
                    "error": f"Rate Limit Exceeded: {e}"
                }
            )
        except APIStatusError as e:
            # API ì‘ë‹µ ìƒíƒœ ì½”ë“œ ì˜¤ë¥˜
            logger.error(f"ì‘ì—… {task_id}: OpenAI API ìƒíƒœ ì˜¤ë¥˜ (Status: {e.status_code}) - {e}", exc_info=True)
            await redis_client.hset(
                TASK_REDIS_KEY,
                mapping={
                    "status": "error",
                    "error": f"OpenAI API Status Error ({e.status_code}): {e.response.text}"
                }
            )
        except APIConnectionError as e:
            # ë„¤íŠ¸ì›Œí¬ ë˜ëŠ” ì—°ê²° ì˜¤ë¥˜
            logger.error(f"ì‘ì—… {task_id}: OpenAI API ì—°ê²° ì˜¤ë¥˜ - {e}", exc_info=True)
            await redis_client.hset(
                TASK_REDIS_KEY,
                mapping={
                    "status": "error",
                    "error": f"OpenAI API Connection Error: {e}"
                }
            )
        except TimeoutError:
             # asyncio ë˜ëŠ” http ë¼ì´ë¸ŒëŸ¬ë¦¬ ë ˆë²¨ì˜ íƒ€ì„ì•„ì›ƒ
            logger.error(f"ì‘ì—… {task_id}: OpenAI API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ", exc_info=True)
            await redis_client.hset(
                TASK_REDIS_KEY,
                mapping={
                    "status": "error",
                    "error": "OpenAI API Request timed out"
                }
            )
        except Exception as e:
            # ê¸°íƒ€ OpenAI ê´€ë ¨ ì˜ˆì™¸
            logger.error(f"ì‘ì—… {task_id}: ì˜ˆì¸¡í•˜ì§€ ëª»í•œ OpenAI API ê´€ë ¨ ì˜¤ë¥˜ - {e}", exc_info=True)
            await redis_client.hset(
                TASK_REDIS_KEY,
                mapping={
                    "status": "error",
                    "error": f"Unexpected OpenAI API Error: {e}"
                }
            )

    except Exception as error:
        # Redis í†µì‹  ì˜¤ë¥˜ ë“± LLM API í˜¸ì¶œ ìì²´ ì´ì „/ì´í›„ ì˜¤ë¥˜
        logger.critical(f"ì‘ì—… {task_id}: ì‘ì—… ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ - {error}", exc_info=True)
        try:
            await redis_client.hset(
                TASK_REDIS_KEY,
                mapping={
                    "status": "critical_processing_error",
                    "error": f"Critical processing error: {error}"
                }
            )
        except Exception as redis_err:
             logger.error(f"ì‘ì—… {task_id}: ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ í›„ Redis ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {redis_err}", exc_info=True)

@router.post("/tasks")
async def create_tasks(prompts: PromptList):
    """í”„ë¡¬í”„íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ íì— ì¶”ê°€í•˜ê³  ì‘ì—… IDë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    task_ids = []

    if not prompts or not prompts.prompts:
         raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="í”„ë¡¬í”„íŠ¸ ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")


    logger.info(f"{len(prompts.prompts)}ê°œì˜ ìƒˆ ì‘ì—… ìƒì„± ìš”ì²­ ìˆ˜ì‹ ")

    for prompt in prompts.prompts:
        task_id = str(uuid.uuid4())
        # íì— ì‘ì—… ì¶”ê°€
        await task_queue.put((task_id, prompt))
        task_ids.append(task_id)
        logger.debug(f"ì‘ì—… {task_id} íì— ì¶”ê°€ë¨")

    logger.info(f"{len(task_ids)}ê°œì˜ ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ íì— ì¶”ê°€ë¨")
    # ì‘ë‹µ ì‹œ ìƒíƒœë¥¼ 'queued' ë“±ìœ¼ë¡œ í‘œì‹œ
    return {"task_ids": task_ids, "status": "queued"}

@router.get("/tasks")
async def get_task_status(task_ids: str, request: Request) -> Dict[str, Union[TaskStatus, Dict[str, str]]]:
    """ì‘ì—… ìƒíƒœë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    logger.info(f"ì‘ì—… ìƒíƒœ ì¡°íšŒ ìš”ì²­ ìˆ˜ì‹  (task_ids: {task_ids})")

    # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì‘ì—… ID ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶„ë¦¬
    task_id_list = [id.strip() for id in task_ids.split(",") if id.strip()]

    if not task_id_list:
         raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="ìœ íš¨í•œ ì‘ì—… IDë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")

    res = {}
    # Redis í´ë¼ì´ì–¸íŠ¸ë¥¼ request.app.stateì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    redis_client = request.app.state.redis_client

    for task_id in task_id_list:
        # Redisì—ì„œ ì‘ì—… ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        try:
            task_data = await redis_client.hgetall(f"task:{task_id}")
            if task_data:
                # TaskStatus ëª¨ë¸ì— ë§ì¶° ë°ì´í„°ë¥¼ êµ¬ì„± (ë˜ëŠ” ì›ì‹œ ë°ì´í„° ë°˜í™˜)
                res[task_id] = TaskStatus(**task_data).model_dump() # Pydantic ëª¨ë¸ ì‚¬ìš© ì˜ˆì‹œ
                # ë˜ëŠ” res[task_id] = task_data # ì›ì‹œ ë°ì´í„° ë°˜í™˜
            else:
                # Redisì— ì‘ì—… ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
                res[task_id] = {"status": "not_found"}
            logger.debug(f"ì‘ì—… {task_id} ìƒíƒœ ì¡°íšŒ ê²°ê³¼: {res[task_id]}")
        except Exception as e:
            logger.error(f"ì‘ì—… {task_id} ìƒíƒœ ì¡°íšŒ ì¤‘ Redis ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            res[task_id] = {"status": "error", "error": "Failed to retrieve status from Redis"}

    return res
```

```python
# app/main.py
from contextlib import asynccontextmanager
from dotenv import load_dotenv
from fastapi import FastAPI

import asyncio
import multiprocessing
import os
import redis.asyncio as redis
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í™˜ê²½ë³€ìˆ˜ ê²€ì¦ ë¡œì§
required_env_vars = ['OPENAI_API_KEY', 'NUM_WORKERS', 'REDIS_HOST', 'REDIS_PORT', 'REDIS_DB']
missing_vars = [var for var in required_env_vars if not os.getenv(var)]
if missing_vars:
    raise ValueError(f"í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {missing_vars}")

# ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ íƒœìŠ¤í¬ ë¦¬ìŠ¤íŠ¸
worker_tasks: list[asyncio.Task] = []

# ë™ì ì¸ ì›Œì»¤ ìˆ˜ ì„¤ì • (asyncio ì›Œì»¤ ìˆ˜ë¥¼ ì˜ë¯¸)
NUM_WORKERS = int(os.getenv('NUM_WORKERS', multiprocessing.cpu_count() * 2))

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬ í•¨ìˆ˜"""
    logger.info("ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘: Redis í´ë¼ì´ì–¸íŠ¸ ë° ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ì´ˆê¸°í™”")

    # Redis í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ë° ìƒíƒœì— ì €ì¥
    try:
        app.state.redis_client = redis.Redis(
            host=os.getenv('REDIS_HOST'),
            port=os.getenv('REDIS_PORT'),
            db=os.getenv('REDIS_DB'),
            decode_responses=True, # ë¬¸ìì—´ë¡œ ë°ì´í„°ë¥¼ ì²˜ë¦¬
        )
        # Redis ì—°ê²° í™•ì¸
        await app.state.redis_client.ping()
        logger.info("Redis í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì„±ê³µ")
    except Exception as e:
        logger.critical(f"Redis í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ë˜ëŠ” ì—°ê²° ì‹¤íŒ¨: {e}", exc_info=True)
        # Redis ì—°ê²° ì‹¤íŒ¨ ì‹œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ì„ ì¤‘ë‹¨í•˜ê±°ë‚˜,
        # API ìš”ì²­ ì‹œ Redis ì—°ê²° ì¬ì‹œë„ ë¡œì§ì„ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.
        # ì—¬ê¸°ì„œëŠ” ë¡œê¹…ë§Œ í•˜ê³  ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ê³„ì† ì§„í–‰í•˜ë„ë¡ í•©ë‹ˆë‹¤.
        # í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ë” ê²¬ê³ í•œ ì²˜ë¦¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        raise e  # ë˜ëŠ” ì ì ˆí•œ fallback ë¡œì§ êµ¬í˜„

    # ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ì‹œì‘
    from routers.router import background_worker, task_queue # router.pyì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    for _ in range(NUM_WORKERS):
        # asyncio.create_taskë¥¼ ì‚¬ìš©í•˜ì—¬ ì›Œì»¤ ì½”ë£¨í‹´ì„ ìŠ¤ì¼€ì¤„ë§í•©ë‹ˆë‹¤.
        task = asyncio.create_task(background_worker(app.state.redis_client, task_queue))
        worker_tasks.append(task)
    logger.info(f"{NUM_WORKERS}ê°œì˜ ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ì‹œì‘ë¨")

    # yieldë¥¼ í†µí•´ ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ë™
    yield

    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ ì •ë¦¬ ì‘ì—…
    logger.info("ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ: ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ë° Redis í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬")

    # íê°€ ë¹Œ ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ê±°ë‚˜, ë‚¨ì€ ì‘ì—…ì„ ì·¨ì†Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì›Œì»¤ íƒœìŠ¤í¬ë“¤ì„ ì·¨ì†Œí•©ë‹ˆë‹¤.
    for task in worker_tasks:
        task.cancel()
    # ì·¨ì†Œê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
    await asyncio.gather(*worker_tasks, return_exceptions=True)
    logger.info("ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ì •ë¦¬ ì™„ë£Œ")

    # Redis í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ
    if hasattr(app.state, 'redis_client') and app.state.redis_client:
        await app.state.redis_client.aclose()
        logger.info("Redis í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ")


# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™”
app = FastAPI(
    title="Asynchronous LLM API",
    description="ë¹„ë™ê¸° LLM ì²˜ë¦¬ë¥¼ ìœ„í•œ API ì„œë²„",
    version="1.0.0",
    swagger_ui_parameters={
        "syntaxHighlight": {
            "theme": "obsidian"
        }
    },
    lifespan=lifespan, # lifespan í•¨ìˆ˜ ë“±ë¡
)

# ë¼ìš°í„° ë“±ë¡
# routers.router íŒŒì¼ì—ì„œ ì •ì˜ëœ router ê°ì²´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
from routers.router import router
app.include_router(router, prefix="/api", tags=["LLM Background"])

# ì´ ë¶€ë¶„ì€ uvicorn ì‹¤í–‰ ì‹œ í•„ìš”í•©ë‹ˆë‹¤.
if __name__ == "__main__":
    import uvicorn
    # ë¡œê¹… ì„¤ì •ì„ lifespanì´ë‚˜ ì´ ë¶€ë¶„ì—ì„œ ì¼ê´„ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
    uvicorn.run("main:app", host="localhost", port=8000, log_level="info") # uvicorn ë¡œê¹… ë ˆë²¨ ì„¤ì •
```

- `POST /api/tasks`ë¡œ ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ë¥¼ ë¹„ë™ê¸° ì²˜ë¦¬ ìš”ì²­
- ê° ì‘ì—…ì€ ë³„ë„ task_idë¡œ Redisì— ìƒíƒœ ì €ì¥
- `GET /api/tasks/{task_id}`ë¡œ ìƒíƒœ/ê²°ê³¼ ì¡°íšŒ
- Redis TTLë¡œ ìë™ ë§Œë£Œ

---

## 6. âš™ ê³ ë ¤ì‚¬í•­ ë° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ {#considerations}

- **ë™ì‹œì„± ì œì–´**:
  - `asyncio.Queue`ì™€ ê³ ì •ëœ ìˆ˜ì˜ ì›Œì»¤ë¥¼ í†µí•´ ë™ì‹œì— ì²˜ë¦¬ë˜ëŠ” ì‘ì—…ì˜ ìˆ˜ë¥¼ ì œí•œ
  - ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ì— ë§ê²Œ `NUM_WORKERS` ê°’ ìµœì í™” (ì¼ë°˜ì ìœ¼ë¡œ CPU ì½”ì–´ ìˆ˜ Ã— 2 ì •ë„ë¡œ ì‹œì‘)
  - ì›Œì»¤ ìˆ˜ê°€ ë§ìœ¼ë©´ ë™ì‹œì„±ì€ ë†’ì•„ì§€ë‚˜ CPU ì˜¤ë²„í—¤ë“œ ë°œìƒ, ì ìœ¼ë©´ í ëŒ€ê¸° ì‹œê°„ ì¦ê°€

- **ì—ëŸ¬ ì²˜ë¦¬**:
  - LLM API í˜¸ì¶œ ê´€ë ¨ ì˜¤ë¥˜(í† í° í•œë„ ì´ˆê³¼, ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ë“±)ì— ëŒ€í•´ ì„¸ë¶„í™”ëœ ì˜ˆì™¸ ì²˜ë¦¬
  - Redis ì—°ê²° ì‹¤íŒ¨ ì‹œ ì§€ìˆ˜ ë°±ì˜¤í”„ ì „ëµìœ¼ë¡œ ì¬ì‹œë„ êµ¬í˜„
  - ì¹˜ëª…ì  ì˜¤ë¥˜ ì‹œ ê²½ê³  ì•Œë¦¼ ì‹œìŠ¤í…œ ì—°ë™

- **ìºì‹± ì „ëµ**:
  - ë™ì¼ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ê²°ê³¼ í•´ì‹œ ê¸°ë°˜ ìºì‹±ìœ¼ë¡œ ì¤‘ë³µ ìš”ì²­ ë°©ì§€
  - ìºì‹œ ì ì¤‘ë¥  ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”
  - ìºì‹œ ë¬´íš¨í™” ì£¼ê¸° ì„¤ì •

- **ì‘ì—… ë§Œë£Œ(TTL)**:
  - Redis TTL ê³„ì¸µí™”: ì‘ì—… ìƒíƒœëŠ” ì§§ê²Œ(24ì‹œê°„), ê²°ê³¼ëŠ” ê¸¸ê²Œ(7ì¼) ìœ ì§€
  - ì¤‘ìš” ì‘ì—… ê²°ê³¼ ì˜êµ¬ ì €ì¥ì†Œ ì—°ë™

- **ë¡œê¹…/ëª¨ë‹ˆí„°ë§**:
  - Prometheus/Grafanaë¡œ í ê¸¸ì´, ì²˜ë¦¬ ì‹œê°„, ì˜¤ë¥˜ìœ¨ ë“± ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
  - êµ¬ì¡°í™”ëœ ë¡œê·¸ë¡œ ë””ë²„ê¹… ìš©ì´ì„± í–¥ìƒ
  - í‰ê·  ì‘ë‹µ ì‹œê°„, P95/P99 ì§€ì—° ì‹œê°„ ë“± ì„±ëŠ¥ ì§€í‘œ ì¶”ì 

- **ë¶€í•˜ í…ŒìŠ¤íŠ¸ ë° ìŠ¤ì¼€ì¼ë§**:
  - ìµœëŒ€ ë¶€í•˜ í…ŒìŠ¤íŠ¸ë¡œ ì‹œìŠ¤í…œ í•œê³„ íŒŒì•…
  - í•„ìš”ì‹œ Redis Cluster êµ¬ì„±ìœ¼ë¡œ ìˆ˜í‰ì  í™•ì¥
  - ê¸‰ê²©í•œ íŠ¸ë˜í”½ ì¦ê°€ì— ëŒ€ë¹„í•œ ë™ì  ì›Œì»¤ ìŠ¤ì¼€ì¼ë§ êµ¬í˜„

- **ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ê´€ë¦¬**:
  - ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì›Œì»¤ ì´ˆê¸°í™”: `/api/tasks` ì—”ë“œí¬ì¸íŠ¸ ì²« í˜¸ì¶œ ì‹œê°€ ì•„ë‹Œ, FastAPIì˜ `lifespan` ì´ë²¤íŠ¸ ë“±ì„ í™œìš©í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ê³¼ í•¨ê»˜ ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ì½”ë£¨í‹´ë“¤ì„ ë¯¸ë¦¬ ìƒì„±í•˜ê³  ì‹¤í–‰í•˜ëŠ” ê²ƒì´ ì•ˆì •ì ì…ë‹ˆë‹¤.
  - ì›Œì»¤ì˜ Graceful shutdown: ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ ì‹¤í–‰ ì¤‘ì¸ ì›Œì»¤ë“¤ì´ í˜„ì¬ ì‘ì—…ì„ ì™„ë£Œí•˜ê±°ë‚˜ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ë„ë¡ ì²˜ë¦¬ ë¡œì§ì„ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.

- **Redis í´ë¼ì´ì–¸íŠ¸ ì¼ê´€ì„±**:
  - ì• í”Œë¦¬ì¼€ì´ì…˜ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬(`lifespan`)ë¥¼ í†µí•´ ì´ˆê¸°í™”ëœ ë‹¨ì¼ ë¹„ë™ê¸° Redis í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬, ëª¨ë“  Redis ì ‘ê·¼(API ì—”ë“œí¬ì¸íŠ¸ ë° ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤)ì—ì„œ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ê³  í´ë¼ì´ì–¸íŠ¸ ë¦¬ì†ŒìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ê²ƒì´ ê¶Œì¥ë©ë‹ˆë‹¤.

---

## 7. ğŸ ë§ˆì¹˜ë©° {#conclusion}

ë¹„ë™ê¸° íŒŒì´ì¬, FastAPI, Redis, Asyncio, ê·¸ë¦¬ê³  OpenAI APIë¥¼ ê²°í•©í•˜ë©´ ëŒ€ê·œëª¨ LLM ê¸°ë°˜ APIë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì„¤ê³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- **ë™ì‹œì„±**ì„ í†µí•œ ë¹ ë¥¸ ì²˜ë¦¬

- **Redis**ë¡œ ì‘ì—… ìƒíƒœ ì¶”ì  ë° ìºì‹±

- **FastAPI**ë¡œ í™•ì¥ì„± ë†’ì€ API ì œê³µ

- **Asyncio**ë¡œ ë„¤íŠ¸ì›Œí¬/IO ë³‘ëª© ìµœì†Œí™”

ì´ êµ¬ì¡°ëŠ” ì˜ë¯¸ ê²€ìƒ‰, ë¬¸ì„œ ìš”ì•½, ì§ˆì˜ì‘ë‹µ ë“± ë‹¤ì–‘í•œ LLM ê¸°ë°˜ ì„œë¹„ìŠ¤ì— ì ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ëŒ€ëŸ‰ ìš”ì²­ ì²˜ë¦¬ì™€ ì‹¤ì‹œê°„ ì‘ë‹µì´ ì¤‘ìš”í•œ í™˜ê²½ì—ì„œ íŠ¹íˆ ê°•ë ¥í•œ ì„ íƒì§€ì…ë‹ˆë‹¤.
