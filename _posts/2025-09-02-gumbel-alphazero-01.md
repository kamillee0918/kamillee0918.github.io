---
layout: post
title: "Gumbel AlphaZero ì†Œê°œ ë° ê¸°ë³¸ íƒìƒ‰ ì•Œê³ ë¦¬ì¦˜"
date: 2025-09-02 12:00:00 +0900
last_modified_at: 2025-09-03 23:44:00 +0900
tags: [AlphaZero, Gumbel, ReinforcementLearning, ì¼ë³¸ì¥ê¸°, íŠœë‹]
toc: true
---

## ğŸ“‘ **Table Of Contents**

- [1. âš™ Gumbel AlphaZeroë€?](#gumbel-alphazero)
- [2. âš™ DeepMind Mctx: JAX ê¸°ë°˜ MCTS ë¼ì´ë¸ŒëŸ¬ë¦¬](#mctx)
  - [2.1. Mctx ì†Œê°œ](#mctx-intro)
  - [2.2. ì„¤ì¹˜ ë°©ë²•](#mctx-install)
- [3. âš™ ê¸°ì¡´ AlphaZeroì˜ í•œê³„](#limitations-of-the-existing-alphazero)
- [4. âš™ Gumbel AlphaZeroì˜ í˜ì‹ ](#innovation-of-gumbel-alphazero)
- [5. âš™ `visualization_demo.py`ë¡œ ì´í•´í•˜ëŠ” íƒìƒ‰ ì•Œê³ ë¦¬ì¦˜](#sample-code)
  - [5.1. Mctxì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œ](#mctx-components)
  - [5.2. `gumbel_muzero_policy` í˜¸ì¶œ ì˜ˆì‹œ](#mctx-example)
- [6. ğŸ ë§ˆì¹˜ë©°](#conclusion)

---

![gumbel_01.png](/images/posts/2025-09-02-gumbel-alphazero-01/gumbel_01.png)

## 1. âš™ Gumbel AlphaZeroë€?

`Gumbel AlphaZero`ëŠ” ê¸°ì¡´ì˜ `AlphaZero`ê°€ ê°€ì§„ ê°•í™”í•™ìŠµì˜ í•œê³„ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ ì œì•ˆëœ ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤. íŠ¹íˆ ì ì€ ìˆ˜ì˜ ì‹œë®¬ë ˆì´ì…˜ë§Œìœ¼ë¡œë„ ì •ì±…(Policy)ì„ ì´ë¡ ì ìœ¼ë¡œ ê°œì„ í•  ìˆ˜ ìˆë‹¤ëŠ” ê°•ë ¥í•œ ì¥ì ì„ ê°€ì§‘ë‹ˆë‹¤.

ì´ ê¸€ì—ì„œëŠ” `Gumbel AlphaZero`ë¥¼ ë„ì…í•˜ëŠ” ê³¼ì • ë° ê·¸ í•µì‹¬ ê°œë…ê³¼ ì•Œê³ ë¦¬ì¦˜ì„ ì •ë¦¬í•©ë‹ˆë‹¤.

## 2. âš™ DeepMind Mctx: JAX ê¸°ë°˜ MCTS ë¼ì´ë¸ŒëŸ¬ë¦¬

`Gumbel AlphaZero`ë¥¼ ë¹„ë¡¯í•œ ìµœì‹  íƒìƒ‰ ì•Œê³ ë¦¬ì¦˜ë“¤ì€ ë”¥ë§ˆì¸ë“œì—ì„œ ê°œë°œí•œ `Mctx` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬í˜„ë˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. `Mctx`ëŠ” JAX ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì–´ Python í™˜ê²½ì—ì„œ ë†’ì€ ì„±ëŠ¥ê³¼ ìœ ì—°ì„±ì„ ì œê³µí•˜ëŠ” MCTS(Monte Carlo Tree Search) ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.

### 2.1. Mctx ì†Œê°œ

`Mctx`ëŠ” MuZeroì™€ ê°™ì€ ê°•ë ¥í•œ ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì„ ì—°êµ¬ìë“¤ì´ ë” ì‰½ê²Œ ì‚¬ìš©í•˜ê³  ë°œì „ì‹œí‚¬ ìˆ˜ ìˆë„ë¡ ë•ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. C++ ë“±ìœ¼ë¡œ ì‘ì„±ëœ ê¸°ì¡´ì˜ ê³ ì„±ëŠ¥ íƒìƒ‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ë‹¬ë¦¬, JAXë¥¼ ì‚¬ìš©í•˜ì—¬ Pythonì˜ í¸ì˜ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„ ì»´íŒŒì¼ì„ í†µí•œ ì„±ëŠ¥ ìµœì í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

### 2.2. í™˜ê²½ êµ¬ì¶•

ì´ ê¸€ì˜ ì˜ˆì œ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•´, WSL2 Ubuntu 22.04 í™˜ê²½ì— [Miniconda](https://docs.conda.io/projects/miniconda/en/latest/index.html)ë¥¼ ì„¤ì¹˜í•˜ê³  `mctx`ë¼ëŠ” ì´ë¦„ì˜ Conda ê°€ìƒí™˜ê²½ì„ ìƒì„±í•©ë‹ˆë‹¤.

```bash
# Conda ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
conda create -n mctx python=3.11
conda activate mctx
```

`visualization_demo.py`ì˜ íƒìƒ‰ íŠ¸ë¦¬ ì‹œê°í™”ì— í•„ìš”í•œ `Graphviz`ì™€ `pygraphviz`ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.

```bash
# 1. ì‹œìŠ¤í…œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (Graphviz)
sudo apt-get update && sudo apt-get install -y graphviz graphviz-dev

# 2. Conda íŒ¨í‚¤ì§€ ì„¤ì¹˜ (pygraphviz)
conda install conda-forge::pygraphviz
```

ë§ˆì§€ë§‰ìœ¼ë¡œ `JAX`, `Chex`, `Mctx`ë¥¼ `pip`ìœ¼ë¡œ ì„¤ì¹˜í•©ë‹ˆë‹¤.

```bash
# 3. Pip íŒ¨í‚¤ì§€ ì„¤ì¹˜

# JAX (NVIDIA GPU í™˜ê²½)
pip install "jax[cuda12]"

# JAX (CPU í™˜ê²½, GPUê°€ ì—†ëŠ” ê²½ìš°)
# pip install jax

# Chex ë° Mctx
pip install chex mctx

# ë˜ëŠ” GitHubì—ì„œ ì§ì ‘ ìµœì‹  ê°œë°œ ë²„ì „ ì„¤ì¹˜
# pip install chex git+https://github.com/google-deepmind/mctx.git
```

## 3. âš™ ê¸°ì¡´ AlphaZeroì˜ í•œê³„

`AlphaZero`ì˜ ê°•í™”í•™ìŠµì€ **UCT(Upper Confidence bounds for Trees)** ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ íƒìƒ‰ì„ ìˆ˜í–‰í•˜ê³ , ê·¸ ê²°ê³¼(ë°©ë¬¸ íšŸìˆ˜)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ì±…ì„ ê°œì„ í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ ë°©ì‹ì€ ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜ê°€ ì¶©ë¶„íˆ ë§ì§€ ì•Šì„ ê²½ìš°, í•™ìŠµì´ ìš°ì—°íˆ ìƒ˜í”Œë§ëœ í–‰ë™ì—ë§Œ ì˜ì¡´í•˜ê²Œ ë˜ì–´ ì •ì±… ê°œì„ ì„ ì´ë¡ ì ìœ¼ë¡œ ë³´ì¥í•  ìˆ˜ ì—†ëŠ” ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤.

ì´ëŠ” ê³§, ì œí•œëœ ì‹œê°„ ì•ˆì— ìµœì ì˜ ìˆ˜ë¥¼ ì°¾ì•„ì•¼ í•˜ëŠ” ì‹¤ì œ ëŒ€êµ­ í™˜ê²½ì—ì„œ ì•½ì ìœ¼ë¡œ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## 4. âš™ Gumbel AlphaZeroì˜ í˜ì‹ 

`Gumbel AlphaZero`ëŠ” ë£¨íŠ¸ ë…¸ë“œ(íƒìƒ‰ì˜ ì‹œì‘ì )ì—ì„œ PUCB(Polynomial Upper Confidence Bound) ëŒ€ì‹  **Gumbel-Top-k**ë¼ëŠ” ìƒˆë¡œìš´ ê¸°ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë” ì ì€ ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œë„ ì •ì±…ì´ ê°œì„ ë  ê²ƒì„ì„ ì´ë¡ ì ìœ¼ë¡œ ë³´ì¥í•©ë‹ˆë‹¤.

ë˜í•œ, íƒìƒ‰ ê³¼ì •ì—ì„œ **ìˆœì°¨ì  ë°˜ê°ë²•(Sequential Halving)**ì„ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ ì œí•œëœ ì‹œë®¬ë ˆì´ì…˜ ì˜ˆì‚°ì„ ê°€ì¥ ìœ ë§í•œ í›„ë³´ ìˆ˜ì— íš¨ìœ¨ì ìœ¼ë¡œ ë°°ë¶„í•©ë‹ˆë‹¤. ì´ ë‘ ê°€ì§€ í•µì‹¬ì ì¸ ë³€í™”ë¥¼ í†µí•´ `Gumbel AlphaZero`ëŠ” ê¸°ì¡´ `AlphaZero`ë³´ë‹¤ íš¨ìœ¨ì ì´ê³  ì•ˆì •ì ì¸ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

## 5. âš™ `visualization_demo.py`ë¡œ ì´í•´í•˜ëŠ” íƒìƒ‰ ì•Œê³ ë¦¬ì¦˜

`Mctx` ê³µì‹ ì €ì¥ì†Œì—ëŠ” `Gumbel AlphaZero`ì˜ ë™ì‘ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” `visualization_demo.py` ì˜ˆì œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ ì½”ë“œëŠ” `Mctx`ì˜ í•µì‹¬ ì •ì±… ì¤‘ í•˜ë‚˜ì¸ `gumbel_muzero_policy`ë¥¼ ì‚¬ìš©í•˜ì—¬ íƒìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

`visualization_demo.py`ë¥¼ ì‹¤í–‰í•˜ë©´ íƒìƒ‰ ê³¼ì •ì´ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì§€ë©°, íƒìƒ‰ ê²°ê³¼ëŠ” `/tmp/search_tree.png`ì— ì €ì¥ë©ë‹ˆë‹¤.

ì¶œë ¥ ì˜ˆì‹œ:

```plain
Starting search.
Selected action: 1
Selected action Q-value: 10.666667
Saving tree diagram to: /tmp/search_tree.png
```

![search_tree.png](/images/posts/2025-09-02-gumbel-alphazero-01/search_tree.png)

### 5.1. Mctxì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œ

`Mctx`ì˜ ì •ì±… í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ì‚¬ìš©ìê°€ ëª‡ ê°€ì§€ êµ¬ì„± ìš”ì†Œë¥¼ ì§ì ‘ ì •ì˜í•˜ì—¬ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” `Mctx`ê°€ íŠ¹ì • ê²Œì„ì´ë‚˜ í™˜ê²½ì— ì¢…ì†ë˜ì§€ ì•Šê³  ë²”ìš©ì ìœ¼ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

- **`RootFnOutput`**: íƒìƒ‰ì„ ì‹œì‘í•˜ëŠ” ë£¨íŠ¸ ë…¸ë“œì˜ ìƒíƒœë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì •ì±… ë„¤íŠ¸ì›Œí¬ê°€ ì¶œë ¥í•˜ëŠ” **ì •ì±… í™•ë¥ (prior_logits)**, **ìƒíƒœ ê°€ì¹˜(value)**, ê·¸ë¦¬ê³  ìƒíƒœë¥¼ í‘œí˜„í•˜ëŠ” **ì„ë² ë”©(embedding)**ì„ í¬í•¨í•©ë‹ˆë‹¤.
- **`recurrent_fn`**: í™˜ê²½ì˜ ë™ì—­í•™ ëª¨ë¸ ì—­í• ì„ í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. í˜„ì¬ ìƒíƒœì˜ `embedding`ê³¼ ì„ íƒëœ `action`ì„ ì…ë ¥ë°›ì•„, ë‹¤ìŒ ìƒíƒœì˜ `embedding`ê³¼ í•¨ê»˜ ì „ì´ ê³¼ì •ì—ì„œ ì–»ëŠ” **ë³´ìƒ(reward)**, **í• ì¸ìœ¨(discount)**, ê·¸ë¦¬ê³  ë‹¤ìŒ ìƒíƒœì˜ **ì •ì±… í™•ë¥ **ê³¼ **ê°€ì¹˜**ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

### 5.2. í™˜ê²½ ì •ì˜

ìƒíƒœ ì „ì´ì™€ ë³´ìƒì€ ì•„ë˜ì™€ ê°™ì´ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

```python
# We will define a deterministic toy environment.
# The deterministic `transition_matrix` has shape `[num_states, num_actions]`.
# The `transition_matrix[s, a]` holds the next state.
transition_matrix = jnp.array([
    [1, 2, 3, 4],
    [0, 5, 0, 0],
    [0, 0, 0, 6],
    [0, 0, 0, 0],
    [0, 0, 0, 0],
    [0, 0, 0, 0],
    [0, 0, 0, 0],
], dtype=jnp.int32)
# The `rewards` have shape `[num_states, num_actions]`. The `rewards[s, a]`
# holds the reward for that (s, a) pair.
rewards = jnp.array([
    [1, -1, 0, 0],
    [0, 0, 0, 0],
    [0, 0, 0, 0],
    [0, 0, 0, 0],
    [0, 0, 0, 0],
    [0, 0, 0, 0],
    [10, 0, 20, 0],
], dtype=jnp.float32)
```

ì´ 7ê°œì˜ ìƒíƒœê°€ ìˆìœ¼ë©°, `transition_matrix`ëŠ” ìƒíƒœ ì „ì´ë¥¼, `rewards`ëŠ” ê° í–‰ë™ì— ëŒ€í•œ ë³´ìƒì„ ì •ì˜í•©ë‹ˆë‹¤.

ë˜í•œ ìƒíƒœ ê°€ì¹˜ì— ëŒ€í•œ í• ì¸ìœ¨ë„ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

```python
# The discount for each (s, a) pair.
discounts = jnp.where(transition_matrix > 0, 1.0, 0.0)

```

`transition_matrix`ì˜ ê°’ì´ 0, ì¦‰ ë‹¤ìŒ ìƒíƒœê°€ ì—†ëŠ” ê²½ìš° í• ì¸ìœ¨ì´ 0ì´ ë©ë‹ˆë‹¤.

### 5.3. ìƒíƒœ ê°€ì¹˜ì˜ ì´ˆê¸°ê°’

ê° ìƒíƒœì˜ ì´ˆê¸° ê°€ì¹˜ëŠ” 15ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” íƒìƒ‰ ì´ˆê¸°ì— ëª¨ë“  ìƒíƒœë¥¼ ë‚™ê´€ì ìœ¼ë¡œ í‰ê°€í•˜ì—¬ íƒí—˜(exploration)ì„ ì¥ë ¤í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.

```python
# Using optimistic initial values to encourage exploration.
values = jnp.full([num_states], 15.0)
```

### 5.4. ì •ì±… ë„¤íŠ¸ì›Œí¬ì˜ ì‚¬ì „ í™•ë¥ 

ê° ìƒíƒœì—ì„œ ì •ì±… ë„¤íŠ¸ì›Œí¬ê°€ ì¶œë ¥í•˜ëŠ” ì‚¬ì „ í™•ë¥ ì˜ logitsì€ 0ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” íƒìƒ‰ ì´ˆê¸° ë‹¨ê³„ì—ì„œ ëª¨ë“  í–‰ë™ì´ ë™ì¼í•œ í™•ë¥ ì„ ê°–ë„ë¡ í•©ë‹ˆë‹¤.

```python
# The prior policies for each state.
all_prior_logits = jnp.zeros_like(rewards)
```

### 5.5. ë£¨íŠ¸ ë…¸ë“œì™€ ìƒíƒœ ì „ì´ í•¨ìˆ˜ í˜¸ì¶œ ì˜ˆì‹œ

`_make_batched_env_model` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë£¨íŠ¸ ë…¸ë“œì™€ ìƒíƒœ ì „ì´ í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

```python
def _make_batched_env_model(
    batch_size: int,
    *,
    transition_matrix: chex.Array,
    rewards: chex.Array,
    discounts: chex.Array,
    values: chex.Array,
    prior_logits: chex.Array):
  """Returns a batched `(root, recurrent_fn)`."""
  chex.assert_equal_shape([transition_matrix, rewards, discounts,
                           prior_logits])
  num_states, num_actions = transition_matrix.shape
  chex.assert_shape(values, [num_states])
  # We will start the search at state zero.
  root_state = 0
  root = mctx.RootFnOutput(
      prior_logits=jnp.full([batch_size, num_actions],
                            prior_logits[root_state]),
      value=jnp.full([batch_size], values[root_state]),
      # The embedding will hold the state index.
      embedding=jnp.zeros([batch_size], dtype=jnp.int32),
  )

  def recurrent_fn(params, rng_key, action, embedding):
    del params, rng_key
    chex.assert_shape(action, [batch_size])
    chex.assert_shape(embedding, [batch_size])
    recurrent_fn_output = mctx.RecurrentFnOutput(
        reward=rewards[embedding, action],
        discount=discounts[embedding, action],
        prior_logits=prior_logits[embedding],
        value=values[embedding])
    next_embedding = transition_matrix[embedding, action]
    return recurrent_fn_output, next_embedding

  return root, recurrent_fn
```

```python
root, recurrent_fn = _make_batched_env_model(
    # Using batch_size=2 to test the batched search.
    batch_size=2,
    transition_matrix=transition_matrix,
    rewards=rewards,
    discounts=discounts,
    values=values,
    prior_logits=all_prior_logits
)
```

ë£¨íŠ¸ ë…¸ë“œëŠ” `RootFnOutput` íƒ€ì…ìœ¼ë¡œ, (ì‚¬ì „ í™•ë¥ , ê°€ì¹˜, ìƒíƒœ ì„ë² ë”©)ì„ ë³´ìœ í•©ë‹ˆë‹¤.

MuZeroì—ì„œëŠ” ì´ ì„ë² ë”©ì´ ìƒíƒœë¥¼ í‘œí˜„í•˜ëŠ” ë²¡í„°ê°€ ë˜ì§€ë§Œ, ì´ ì˜ˆì œì—ì„œëŠ” ìƒíƒœì˜ ì¸ë±ìŠ¤ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

ìƒíƒœ ì „ì´ í•¨ìˆ˜ `recurrent_fn`ì€ í˜„ì¬ ìƒíƒœì˜ `embedding`ê³¼ ì„ íƒëœ `action`ì„ ì…ë ¥ë°›ì•„, ì „ì´ ê³¼ì •ì—ì„œ ì–»ëŠ” ì •ë³´(`RecurrentFnOutput`)ì™€ ë‹¤ìŒ ìƒíƒœì˜ `embedding`ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

ë°°ì¹˜ ë‹¨ìœ„ íƒìƒ‰ì„ ìœ„í•´ ê° ë°ì´í„°ì˜ ì²« ë²ˆì§¸ ì°¨ì›ì€ ë°°ì¹˜ í¬ê¸°ê°€ ë©ë‹ˆë‹¤.

### 5.6. `gumbel_muzero_policy` í˜¸ì¶œ ì˜ˆì‹œ

`visualization_demo.py`ì—ì„œëŠ” ìœ„ì—ì„œ ì •ì˜í•œ êµ¬ì„± ìš”ì†Œë“¤ì„ `gumbel_muzero_policy`ì— ì „ë‹¬í•˜ì—¬ íƒìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

```python
# Running the search.
policy_output = mctx.gumbel_muzero_policy(
    params=(),
    rng_key=rng_key,
    root=root,
    recurrent_fn=recurrent_fn,
    num_simulations=FLAGS.num_simulations,
    max_depth=FLAGS.max_depth,
    max_num_considered_actions=FLAGS.max_num_considered_actions,
)
```

ì¸ìˆ˜ëŠ” `rng_key`, ë£¨íŠ¸ ë…¸ë“œ(`root`), ìƒíƒœ ì „ì´ í•¨ìˆ˜(`recurrent_fn`), ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜(`num_simulations`), íƒìƒ‰ ê¹Šì´(`max_depth`), ë£¨íŠ¸ ë…¸ë“œì˜ ìµœëŒ€ í–‰ë™ ìˆ˜(`max_num_considered_actions`)ì…ë‹ˆë‹¤.

ì°¸ê³ ë¡œ `rng_key`ëŠ” ë‚œìˆ˜ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.

íƒìƒ‰ì´ ì™„ë£Œë˜ë©´ `policy_output` ê°ì²´ì— ê²°ê³¼ê°€ ë‹´ê²¨ ë°˜í™˜ë©ë‹ˆë‹¤. `policy_output.action`ì€ íƒìƒ‰ì„ í†µí•´ ê²°ì •ëœ ìµœì ì˜ í–‰ë™ì„, `policy_output.action_weights`ëŠ” ì •ì±… ë„¤íŠ¸ì›Œí¬ í•™ìŠµì— ì‚¬ìš©ë  ìˆ˜ ìˆëŠ” ëª©í‘œ í™•ë¥ ê°’ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.

## 6. ğŸ ë§ˆì¹˜ë©°

ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” `Gumbel AlphaZero`ì˜ ê¸°ë³¸ ê°œë…ê³¼ ê·¸ ê¸°ë°˜ì´ ë˜ëŠ” `Mctx` ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ëŒ€í•´ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤. `Mctx`ì˜ ì„¤ì¹˜ ë°©ë²•ê³¼ `visualization_demo.py` ì˜ˆì œë¥¼ í†µí•´ íƒìƒ‰ ì•Œê³ ë¦¬ì¦˜ì´ ì–´ë–¤ êµ¬ì„± ìš”ì†Œë“¤ì„ í•„ìš”ë¡œ í•˜ê³  ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ ì‚´í´ë³´ì•˜ìŠµë‹ˆë‹¤.

ë‹¤ìŒ í¬ìŠ¤íŠ¸ì—ì„œëŠ” `Gumbel AlphaZero`ì˜ í•µì‹¬ì´ë¼ í•  ìˆ˜ ìˆëŠ” **í–‰ë™ ì„ íƒ(Action Selection)** ì•Œê³ ë¦¬ì¦˜, íŠ¹íˆ `Gumbel-Top-k`ì™€ `ìˆœì°¨ì  ë°˜ê°ë²•`ì— ëŒ€í•´ ë” ìì„¸íˆ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.
