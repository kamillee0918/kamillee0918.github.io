---
layout: post
title: Bonanza 메서드 해설
date: 2023-09-08 12:22 +0800
last_modified_at: 2023-09-08 12:35 +0800
tags: [Shogi, Deep Learning]
toc: true
---

## Bonanza 메서드 해설

컴퓨터 쇼기(일본 장기)는 예전부터 관심있게 지켜보았기 때문에, 지난 2017년에 개최되었던 제4회 전왕전(電王戦)을 되짚어보려 합니다.

당시 명인(名人) 타이틀을 보유한 사토 아마히코(佐藤天彦)는 컴퓨터 쇼기 소프트인 Ponanza(ポナンザ)에게 패하였고, 대국에서 사용된 버전의 경우에는 탐색 부분은 미니맥스 알고리즘(Minimax Algorithm)의 개선판이 평가함수를 기계학습으로 최적화하는 방법으로 작성되었다고 합니다.

미니맥스 알고리즘의 병렬화 혹은 고속화는 오래 전부터 개선되어 왔고, 체스 프로그램 등에서 자주 사용됩니다.

쇼기 프로그램에서도 기본적으로는 같은 맥락이며 컴퓨터 쇼기에서의 기술적인 진보는 체스만큼은 아니었다고 생각합니다.

평가함수에 관해서는 2006년 Bonanza 등장 이전에는 개발자가 일일이 로직을 짜고 파라미터 등을 조절하는 것이 보통이었지만, Bonanza는 왕(King) 기물을 중심으로 특정 말의 기물들이 어떠한 형태(囲い)로 배치되었는지를 KPP(King Piece Piece)라고 언급한 바 있습니다. 이러한 특징들을 선형화시켜 프로 기사들의 기보로부터 기계학습시킨 것으로 큰 파장을 일으켰습니다.

이 소프트의 등장 이후로 대부분의 쇼기 프로그램은 Bonanza에서 비롯되었다고 할 수 있습니다.

Ponanza는 다른 쇼기 프로그램의 진보된 형태이며 Bonanza와는 다르게 평가함수 학습에 프로 기사의 기보가 사용되지 않았고, Ponanza 간 대국으로 강화학습 형태로 진화시켜 왔다고 합니다.

이번 포스팅에서는 Bonanza가 선택한 기계학습 방법(통칭 Bonanza 메서드)에 관하여 설명하도록 하겠습니다.

[Jekyll 공식 홈페이지](https://jekyllrb.com/)
